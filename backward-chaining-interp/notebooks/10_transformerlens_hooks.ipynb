{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6982ee6b-bfd6-4f7c-8781-ba75d050029b",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa664f-2bf9-40b4-ae25-4b475e09a02d",
   "metadata": {},
   "source": [
    "Goal: touch `TransformerLens` hook API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf533e2-20f3-41ce-b703-445b194f3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST_BATCHES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b33ffb-f5dd-40e3-bd7c-35587263887a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63604638-b89c-432b-a4a3-39ade890fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e74adb0-97b3-441c-b0bb-27eed0077817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lovely-tensors\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2f9134-d8d7-45a6-afbf-806555ab578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf238670-f8e5-4bb4-a450-64db69b241e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5562d67e-f650-42d1-8a7b-6cb727a1610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tree import list2tree\n",
    "from src.tree_dataset import TreeDataset, parse_input_idx, input_tokens_to_tree, tree_to_edges\n",
    "from src.utils import seed_all\n",
    "\n",
    "\n",
    "from src.trainer import accuracy_by_depth\n",
    "from src.trainer import TreeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1174a691-06ed-4e63-86b8-551a95818dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed: 42\n",
      "n_nodes: 16\n",
      "model:\n",
      "  d_model: 128\n",
      "  d_head: 128\n",
      "  n_layers: 6\n",
      "  act_fn: gelu\n",
      "  attention_dir: causal\n",
      "optimizer:\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.01\n",
      "batch_size: 64\n",
      "epoch_len_steps: 5000\n",
      "checkpoint_every_epoch: 2\n",
      "device: cpu\n",
      "debug: false\n",
      "use_wandb: true\n",
      "wandb:\n",
      "  project: reasoning-mech-interp\n",
      "  name: 00_6L_nodes=16\n",
      "max_iters: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf = OmegaConf.load('../conf/00_reproduce_6L_nodes=16.yaml')\n",
    "\n",
    "# Output is identical to the YAML file\n",
    "conf.n_nodes = 16\n",
    "conf.device = 'cpu'\n",
    "print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf0ff74-5c8a-4ea9-9e7a-268d610ce0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPRODUCED_MODEL_CKPT = '../checkpoints/reasoning-mech-interp__2024-04-10_16-10-20/00_6L_nodes=16__step=220000.pt'\n",
    "# REPRODUCED_MODEL_CKPT = '../checkpoints/reasoning-mech-interp__2024-04-12_14-26-20/00_6L_nodes=16__deep_trees__step=9256.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91de251-bf02-4af9-8678-fe35f63a8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_RUN = False\n",
    "USE_WANDB = (not DEV_RUN) and conf.use_wandb\n",
    "device = conf.device\n",
    "\n",
    "CHECKPOINT_ROOT = Path('../checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872cae4e-57b3-452b-b6fc-ed07dd774032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED=42\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = conf['random_seed']\n",
    "print(f'{RANDOM_SEED=}')\n",
    "seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ab32a1-357a-4d3b-a281-73d3684d7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = TreeTrainer(conf)\n",
    "\n",
    "tokenizer = trainer.dataset.tokenizer\n",
    "\n",
    "tok = tokenizer.tokenize\n",
    "detok = tokenizer.detokenize\n",
    "\n",
    "\n",
    "ROOT_DELIM_TOKEN_IDX = trainer.tok([':'])[0]\n",
    "\n",
    "state_dict = torch.load(REPRODUCED_MODEL_CKPT)\n",
    "trainer.model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eadea4dd-846b-4e6f-bb2d-00a74547a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_baseline_model(device='cpu'):\n",
    "    n_states = 16\n",
    "    max_seq_length = n_states * 4 + 2\n",
    "    \n",
    "    number_tokens = sorted([str(i) for i in range(n_states)], key=lambda x: len(x), reverse=True)\n",
    "    idx2tokens = [\",\", \":\", \"|\"] + [f\">{t}\" for t in number_tokens] + number_tokens\n",
    "    tokens2idx = {token: idx for idx, token in enumerate(idx2tokens)}\n",
    "    \n",
    "    \n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers=6,\n",
    "        d_model=128,\n",
    "        n_ctx=max_seq_length - 1,\n",
    "        n_heads=1,\n",
    "        d_mlp=512,\n",
    "        d_head=128,\n",
    "        #attn_only=True,\n",
    "        d_vocab=len(idx2tokens),\n",
    "        device=device,\n",
    "        attention_dir= \"causal\",\n",
    "        act_fn=\"gelu\",\n",
    "    )\n",
    "    model = HookedTransformer(cfg)\n",
    "    \n",
    "    model.load_state_dict(torch.load(\"/Users/mykhailokilianovskyi/src/backward-chaining-circuits/model.pt\", map_location=torch.device(device)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99495bf3-1119-460b-b8ea-7cad96dd6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "from torch.utils.data import IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195643c7-94ca-4c10-91a9-7c93e36e7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from src.tree import TreeNode\n",
    "from src.utils import seed_all\n",
    "from src.tree_dataset import random_tree_of_depth, DeepTreeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73169e4c-d9d1-4059-ad23-a74ec4b99071",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_dataset = DeepTreeDataset(n_nodes=16, possible_depths=(15,14,13))\n",
    "deep_tree_dataloader = DataLoader(deep_dataset, batch_size=conf['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbe8924-5d3f-4d54-9279-b2921acf6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = load_baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78179a90-48b0-4e5a-86fb-51fc41dca63e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd08db9e-6131-47eb-ad68-53b2446be9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(n_features, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Assuming n_features is the number of features in your dataset and n_classes is the number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53f53c9-b513-46ba-9e2b-bedc706476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def run_logreg(X,y, num_epochs=5, verbose=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    logreg = LogisticRegressionModel(X_train.shape[1], len(np.unique(y_train)))\n",
    "    \n",
    "    logreg_train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(logreg_train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    logreg_test_dataset = TensorDataset(X_test, y_test)\n",
    "    logreg_test_loader = DataLoader(logreg_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(logreg.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        logreg.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = logreg(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in logreg_test_loader:\n",
    "    \n",
    "            with torch.inference_mode():\n",
    "                outputs = logreg(inputs)\n",
    "    \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        epoch_loss = running_loss / len(logreg_test_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_accuracy:.2f}%')\n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135ffb9b-580b-4e39-94e3-c181700f90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_idx2token = trainer.dataset.tokenizer.idx2token\n",
    "\n",
    "\n",
    "n_states = 16\n",
    "bas_max_seq_length = n_states * 4 + 2\n",
    "\n",
    "number_tokens = sorted([str(i) for i in range(n_states)], key=lambda x: len(x), reverse=True)\n",
    "idx2tokens = [\",\", \":\", \"|\"] + [f\">{t}\" for t in number_tokens] + number_tokens\n",
    "tokens2idx = {token: idx for idx, token in enumerate(idx2tokens)}\n",
    "\n",
    "from src.tree_dataset import PAD_TOKEN\n",
    "\n",
    "\n",
    "token2bastoken = {k.replace('>', '→'):k for k in tokens2idx.keys()}\n",
    "token2bastoken[PAD_TOKEN] = ','\n",
    "\n",
    "\n",
    "\n",
    "idx2basidx = {}\n",
    "for idx, our_tok in our_idx2token.items():\n",
    "    bastoken = token2bastoken[our_tok]\n",
    "    basidx = tokens2idx[bastoken]\n",
    "    idx2basidx[idx] = basidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fbe4d6-55be-411c-9d10-54d92fb340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_batch_train_step(baseline_model, batch):\n",
    "    \n",
    "    input_idx = batch['input_idx'][..., :bas_max_seq_length].clone().to(device)\n",
    "    mask = batch['task_mask'][..., :bas_max_seq_length].clone().to(device)\n",
    "\n",
    "    input_idx.apply_(lambda i: idx2basidx[i])\n",
    "\n",
    "    inputs = input_idx[:, :-1]\n",
    "    \n",
    "    out_mask = mask[:, 1:]\n",
    "    targets = input_idx[:, 1:][out_mask]\n",
    "    \n",
    "    \n",
    "    # print(input_idx[:1, :4])\n",
    "    outputs = baseline_model(inputs)\n",
    "    \n",
    "    predictions = outputs[out_mask]\n",
    "    \n",
    "    loss = F.cross_entropy(predictions, targets)\n",
    "\n",
    "    is_correct = (predictions.argmax(dim=-1) == targets)\n",
    "    accuracy_mean = is_correct.float().mean()\n",
    "    metrics = accuracy_by_depth(outputs, input_idx, out_mask)\n",
    "    metrics['accuracy/mean'] = accuracy_mean.item()\n",
    "\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89260abd-a062-4d69-a8da-19770605cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge2idx)=256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_DELIM_TOKEN_IDX = trainer.tok([':'])[0]\n",
    "\n",
    "def extract_edges(sample_input_idx):\n",
    "    upper_task_bound = sample_input_idx.tolist().index(ROOT_DELIM_TOKEN_IDX) + 2\n",
    "    prompt = trainer.detok(sample_input_idx)[:upper_task_bound]\n",
    "    \n",
    "    i = 2\n",
    "    \n",
    "    edges = []\n",
    "    \n",
    "    while i < len(prompt) and prompt[i] != '|':\n",
    "        edge = (prompt[i-2], prompt[i-1])\n",
    "        edges.append(edge)\n",
    "        i += 3\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "n_nodes = 16\n",
    "\n",
    "edges = [(str(i), '→'+str(j)) for i in range(n_nodes) for j in range(n_nodes)]\n",
    "\n",
    "edge2idx = {e:i for i,e in enumerate(edges)}\n",
    "\n",
    "idx2edge = {i:e for e,i in edge2idx.items()}\n",
    "print(f'{len(edge2idx)=}')\n",
    "\n",
    "def get_first_node(edge_idx): return int(idx2edge[edge_idx][0])\n",
    "def get_second_node(edge_idx): return int(idx2edge[edge_idx][1][1:])\n",
    "    \n",
    "\n",
    "def get_edge_labels(batch):\n",
    "    input_idx = batch['input_idx']\n",
    "    edge_batch = []\n",
    "    for row in input_idx:\n",
    "        edges = extract_edges(row)\n",
    "        edges = [edge2idx[e] for e in edges]\n",
    "        edge_batch.append(edges)\n",
    "    return torch.tensor(edge_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d647c-fce4-4e38-b960-6c9ae407fc94",
   "metadata": {},
   "source": [
    "## Check that goal node is moved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856d319-f039-48ca-8dad-7ec47e2cbd9d",
   "metadata": {},
   "source": [
    "### Reproduce \"edge token\" detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fecb21c-4860-45fe-a4dc-dd87a023a627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[14] i64 x∈[2, 41] μ=21.500 σ=12.550\n",
       "tensor([ 2,  5,  8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_token_idx = torch.arange(2, 14*3, 3)\n",
    "third_token_idx.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e32bf41-bd97-476c-bf91-23de574db284",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_keys = [{'key': 'resid_post', \"n\": n} for n in range(6)]\n",
    "cache_keys = [{'key': 'embed', 'n': None}] + cache_keys\n",
    "cache_keys = [\n",
    "    {'key': 'embed', 'n': None}, # just embeddings as a control experiment\n",
    " {'key': 'resid_post', 'n': 0},\n",
    " {'key': 'resid_post', 'n': 1},\n",
    " {'key': 'resid_post', 'n': 2},\n",
    " {'key': 'resid_post', 'n': 3},\n",
    " {'key': 'resid_post', 'n': 4},\n",
    " {'key': 'resid_post', 'n': 5}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13f163-131e-422e-aa58-ec944ef87e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ab3a0db-231d-4d82-8acc-96e3d023d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in deep_tree_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed3d112f-f6cb-47b4-a76d-8ba451a0294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.inference_mode()\n",
    "def get_cache_baseline_model(batch, baseline_model):\n",
    "    input_idx = batch['input_idx'][..., :bas_max_seq_length].clone().to(device)\n",
    "    mask = batch['task_mask'][..., :bas_max_seq_length].clone().to(device)\n",
    "\n",
    "    input_idx.apply_(lambda i: idx2basidx[i])\n",
    "\n",
    "    inputs = input_idx[:, :-1]\n",
    "    \n",
    "    out_mask = mask[:, 1:]\n",
    "    targets = input_idx[:, 1:][out_mask]\n",
    "    \n",
    "    \n",
    "    # print(input_idx[:1, :4])\n",
    "    # outputs = baseline_model(inputs)\n",
    "    \n",
    "    outputs, cache = baseline_model.run_with_cache(inputs)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e27d24f4-e90b-480f-9b8e-aefe3465dc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[14] i64 x∈[1, 40] μ=20.500 σ=12.550\n",
       "tensor([ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_node_idx = torch.arange(1, 14*3, 3)\n",
    "second_node_idx.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "505fd1d2-f257-40d0-9259-5fcd423ef24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[14] i64 x∈[2, 41] μ=21.500 σ=12.550\n",
       "tensor([ 2,  5,  8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_idx = torch.arange(2, 14*3, 3)\n",
    "pad_token_idx.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ad676e-4b66-468a-917e-30601a78ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = conf.model.d_model\n",
    "\n",
    "\n",
    "def extract_Ln_second_node_xy(batch, baseline_model, key='resid_post', n=0):\n",
    "    cache = get_cache_baseline_model(batch, baseline_model)\n",
    "    resid_act0 = cache[key, n]\n",
    "    \n",
    "    X = resid_act0[:, second_node_idx].reshape(-1, d_model)\n",
    "    y = get_edge_labels(batch).reshape(-1)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "def extract_Ln_pad_token_xy(batch, baseline_model, key='resid_post', n=0):\n",
    "    cache = get_cache_baseline_model(batch, baseline_model)\n",
    "    resid_act0 = cache[key, n]\n",
    "    \n",
    "    X = resid_act0[:, pad_token_idx].reshape(-1, d_model)\n",
    "    y = get_edge_labels(batch).reshape(-1)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6deb81f-c11d-4c62-a84f-9ecbe3b6691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = load_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21644fb-f655-4e09-a57c-a04b2a454f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77ae988a-22b9-482f-9b57-51dfdaaf7c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8705e35f1b4eb4ba341d40337ece0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 7.059151785714286, 'acc_node_1': 100.0, 'layer_name': 'key=embed n=None'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b598e6322a4b8d971f077a24335a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=0'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955909f4caf344f486edfc4e3cc50c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=1'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bcd8a659fa4137a6c2d8acd9355046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=2'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f8c5bc095f4435be1a28176f49cd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83adf17a411a4a1b9800145ec1b8ee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=4'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fc427b6cf044f4950254be164f7cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric={'acc_node_0': 100.0, 'acc_node_1': 100.0, 'layer_name': 'key=resid_post n=5'}\n",
      "extract_Ln_second_node_xy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_node_0</th>\n",
       "      <th>acc_node_1</th>\n",
       "      <th>layer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.059152</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=embed n=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>key=resid_post n=5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_node_0  acc_node_1          layer_name\n",
       "0    7.059152       100.0    key=embed n=None\n",
       "1  100.000000       100.0  key=resid_post n=0\n",
       "2  100.000000       100.0  key=resid_post n=1\n",
       "3  100.000000       100.0  key=resid_post n=2\n",
       "4  100.000000       100.0  key=resid_post n=3\n",
       "5  100.000000       100.0  key=resid_post n=4\n",
       "6  100.000000       100.0  key=resid_post n=5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for cache_key in cache_keys:\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i,batch in tqdm(zip(range(N_TEST_BATCHES), deep_tree_dataloader), total=N_TEST_BATCHES):\n",
    "        Xbatch, ybatch = extract_Ln_second_node_xy(batch, baseline_model, **cache_key)\n",
    "    \n",
    "        X.append(Xbatch)\n",
    "        y.append(ybatch)\n",
    "    \n",
    "    \n",
    "    X = torch.cat(X)\n",
    "    y = torch.cat(y)\n",
    "    \n",
    "    y_first_node = torch.tensor( [get_first_node(i.item()) for i in y] )\n",
    "    y_second_node = torch.tensor( [get_second_node(i.item()) for i in y] )\n",
    "\n",
    "    acc_node0 = run_logreg(X, y_first_node)\n",
    "    acc_node1 = run_logreg(X, y_second_node)\n",
    "\n",
    "\n",
    "    layer_name = ''.join ( [f'{k}={v} ' for k,v in cache_key.items()] )[:-1]\n",
    "    metric = {'acc_node_0': float(acc_node0), 'acc_node_1': float(acc_node1), 'layer_name':layer_name}\n",
    "    print(f'{metric=}')\n",
    "\n",
    "    accuracies.append(metric)\n",
    "\n",
    "print('extract_Ln_second_node_xy')\n",
    "pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cd958-0720-4928-bfba-1f3daeef3282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5390ab7b-c36f-43a5-a5a6-f28355193320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as t\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from typing import Optional, Callable, Union, List, Tuple\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89786369-6ce9-470e-8d47-e9fcf74fee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_lr(step, steps):\n",
    "    return (1 - (step / steps))\n",
    "\n",
    "def constant_lr(*_):\n",
    "    return 1.0\n",
    "\n",
    "def cosine_decay_lr(step, steps):\n",
    "    return np.cos(0.5 * np.pi * step / (steps - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55e030d1-4670-43a3-8882-39939d9f8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AutoEncoderConfig:\n",
    "    n_instances: int\n",
    "    n_input_ae: int\n",
    "    n_hidden_ae: int\n",
    "    l1_coeff: float = 0.5\n",
    "    tied_weights: bool = False\n",
    "    weight_normalize_eps: float = 1e-8\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    W_enc: Float[Tensor, \"n_instances n_input_ae n_hidden_ae\"]\n",
    "    W_dec: Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]\n",
    "    b_enc: Float[Tensor, \"n_instances n_hidden_ae\"]\n",
    "    b_dec: Float[Tensor, \"n_instances n_input_ae\"]\n",
    "\n",
    "\n",
    "    def __init__(self, cfg: AutoEncoderConfig):\n",
    "        '''\n",
    "        Initializes the two weights and biases according to the type signature above.\n",
    "\n",
    "        If self.cfg.tied_weights = True, then we only create W_enc, not W_dec.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "\n",
    "    def normalize_and_return_W_dec(self) -> Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]:\n",
    "        '''\n",
    "        If self.cfg.tied_weights = True, we return the normalized & transposed encoder weights.\n",
    "        If self.cfg.tied_weights = False, we normalize the decoder weights in-place, and return them.\n",
    "\n",
    "        Normalization should be over the `n_input_ae` dimension, i.e. each feature should have a noramlized decoder weight.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, h: Float[Tensor, \"batch_size n_instances n_input_ae\"]):\n",
    "        '''\n",
    "        Runs a forward pass on the autoencoder, and returns several outputs.\n",
    "\n",
    "        Inputs:\n",
    "            h: Float[Tensor, \"batch_size n_instances n_input_ae\"]\n",
    "                hidden activations generated from a Model instance\n",
    "\n",
    "        Returns:\n",
    "            l1_loss: Float[Tensor, \"batch_size n_instances\"]\n",
    "                L1 loss for each batch elem & each instance (sum over the `n_hidden_ae` dimension)\n",
    "            l2_loss: Float[Tensor, \"batch_size n_instances\"]\n",
    "                L2 loss for each batch elem & each instance (take mean over the `n_input_ae` dimension)\n",
    "            loss: Float[Tensor, \"\"]\n",
    "                Sum of L1 and L2 loss (with the former scaled by `self.cfg.l1_coeff). We sum over the `n_instances`\n",
    "                dimension but take mean over the batch dimension\n",
    "            acts: Float[Tensor, \"batch_size n_instances n_hidden_ae\"]\n",
    "                Activations of the autoencoder's hidden states (post-ReLU)\n",
    "            h_reconstructed: Float[Tensor, \"batch_size n_instances n_input_ae\"]\n",
    "                Reconstructed hidden states, i.e. the autoencoder's final output\n",
    "        '''\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a65847-ac10-4a30-836d-8516fc6b07de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
