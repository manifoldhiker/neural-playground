random_seed: 42
n_nodes: 8
model:
  d_model: 768
  d_head: 64
  attn_only: true
  n_layers: 2
  act_fn: gelu
  attention_dir: causal
optimizer:
  lr: 0.001
  weight_decay: 0.01
batch_size: 64
epoch_len_steps: 5000
checkpoint_every_epoch: 1
device: mps
debug: false
use_wandb: true
wandb:
  project: reasoning-mech-interp
  name: 02_attn_only_2L_nodes=8
max_iters: null
